---

# This playbook aims to implement a flexible bare-metal setup.

# For this, we need some way to execute comamnds on the system, as it is, well,
# bare (or in any unknown state).
#
# For newly aquired root servers, this usually is an NFS rescue system.
# We assume that we're booted into one such system, and that our inventory has
# that rescue system access configured as 'rescue-{{ inventory_hostname }}' and
# that we have sufficient credentials to connect there. That rescue system's
# SSH host key is ignored, as it's usually a throwaway hostkey anyway and we
# don't have any way to verify it.
#
# Bootstrapping of the remote system will happen in a number of steps:
# 1) before we begin, we check whether we actually should run for this system
# 2) then, prepare the disk devices by stopping whatever is still using it,
#    partitioning them, formatting, encrypting, whatever. this step mounts our
#    filesystems so that we can start installing the operating system
# 3) the operating system is installed into the prepared disks with debootstrap
# 4) setup the chroot from the outside so that we can connect there in the next
#     step. this creates an ansible role account, sets up sshd and sudo.
# 5) this secondary ssh server is used to do basic preparation of the chroot
#    from within (bootloaders, networking)

- hosts: 'reimage_nfs'
  gather_facts: no
  name: Verify permissions and access to target system

  tasks:
    - name: Verify magic hostvar allowing us to wipe the target
      assert:
        that:
          - may_wipe_system == "YesWipeSystem"

    #- include: include/use_hetzner.yml name={{ inventory_hostname }} trust=true

    - set_fact:
        jumphost: 'rescue-{{ inventory_hostname }}'


    # As we assume that the target system is bootet into an disposable rescue
    # system, remove the ssh hostkeys for that rescue system from the
    # ~/.ssh/known_hosts file and enter the currently active ones.
    # sadly, most rescue systems don't expose the ssh fingerprint in any way.

    - when: USE_trustanysshkey|default(true)|bool
      block:
        # FIXME this records a hash for the IP address of the target system. this
        # should better go to /etc/ssh/ssh_known_hosts
        - name: fetch remote ssh host key for rescue host
          delegate_to: localhost
          become: false
          # use the ansible_ssh_host var here, as inventory_hostname may not be
          # resolvable yet
          shell: ssh-keyscan -t rsa {{ ansible_ssh_host }} | grep -v '^#' | grep -v '^no hostkey alg$'
          register: hostkeys
          changed_when: false
          check_mode: no

        - name: Update current ssh host key for rescue host
          # FIXME this doesn't work correctly when hostkeys.stdout contains more
          #       than one key
          delegate_to: localhost
          become: false
          lineinfile:
            dest: "{{ lookup('env', 'HOME' )}}/.ssh/known_hosts"
            backup: yes
            line: '{{jumphost}},{{ hostkeys.stdout }}'
            regexp: '{{ ansible_ssh_host }}'

    - name: Set hostname of remote system
      # Connect to rescue system and update the hostname.
      # Primarilly, this is to check whether we can connect at all: if this step
      # fails, you're probably running an older ansible version which does not
      # set the remote user name for the delegation, or can't connect there for
      # some other reason.
      # FIXME this assumes that the jumphost is disposable and it's own
      #       hostname doesn't matter. this is not the case for actual
      #       jumphosts (eg when creating VMs)
      hostname: "name={{ inventory_hostname }}"
      delegate_to: '{{ jumphost }}'

    - name: Install software on jumphost needed to setup the target system
      apt: pkg={{ item }}
      delegate_to: '{{ jumphost }}'
      with_items:
        - dosfstools
        - cryptsetup
        - debootstrap


- hosts: 'reimage_nfs'
  gather_facts: no
  name: Partition disks and install base system
  tasks:

    - include: include/disk-autodetect-gpt+raid.yml

    ###########################################################################
    ## Scene 2: install target system os into chroot

    - name: debootstrap base system
      command: debootstrap --include sudo,openssh-server,python,aptitude {{ target_release }} {{ dir_root }} {{ target_mirror }}
      delegate_to: '{{ jumphost }}'

###############################################################################
## 4) Start in-chroot sshd so we can connect there

    - command: 'mount --bind /{{ item }} {{ dir_root }}/{{ item }}'
      with_items:
        - dev
        - dev/pts
        - proc
        - sys
      delegate_to: '{{ jumphost }}'

    - name: switch ssh port to 516
      lineinfile: "dest={{ dir_root }}/etc/ssh/sshd_config line='Port 516' regexp='^Port'"
      delegate_to: '{{ jumphost }}'

    - command: chroot {{ dir_root }} service ssh start
      delegate_to: '{{ jumphost }}'

    - name: fetch remote ssh host key
      delegate_to: localhost
      become: false
      # ansible resolves ansible_ssh_host to the delegate here, which is localhost. that's not what we want.
      shell: ssh-keyscan -t ecdsa -p 516 {{ ansible_ssh_host }} | grep -v '^#' | grep -v '^no hostkey alg$'
      register: hostkeys
      changed_when: false

    - name: update current ssh host key
      delegate_to: localhost
      become: false
      # FIXME this doesn't work correctly when hostkeys.stdout contains more than one key
      lineinfile:
        dest: "{{ lookup('env', 'HOME' )}}/.ssh/known_hosts"
        backup: yes
        line: '{{ ansible_ssh_host }},{{ hostkeys.stdout }}'
        regexp: '{{ ansible_ssh_host }},{{ inventory_hostname }}'

    # pre-play role/prepare

    - name: Add ansible role account
      command: 'chroot {{ dir_root }} adduser --uid 1200 --disabled-password --gecos "ansible user" {{ ansible_role_account }}'
      args:
        creates: '{{ dir_root }}/home/{{ ansible_role_account }}'
      delegate_to: '{{ jumphost }}'

    - name: Create SSH directory
      # copy with wrong file modes as we're copying into the rescue system. will be fixed below
      file: path={{ dir_root }}/home/{{ ansible_role_account }}/.ssh state=directory owner=root mode=755
      delegate_to: '{{ jumphost }}'

    - name: Copy authorized_keys for ansible remote user
      # copy with wrong file modes as we're copying into the rescue system. will be fixed below
      copy:
        src: files/ansible_authorized_keys
        dest: '{{ dir_root }}/home/{{ ansible_role_account }}/.ssh/authorized_keys'
        owner: root
        group: root
        mode: 0444
      delegate_to: '{{ jumphost }}'

    - name: Copy sudoers
      template: src=templates/sudoers.j2 dest={{ dir_root }}/etc/sudoers.d/ansible group=root owner=root mode=440
      delegate_to: '{{ jumphost }}'

###############################################################################
## 5) Setup target system to be rebootable

- hosts: 'reimage_nfs'
  name: Sort host into group depending on its ansible_distribution_release
  # when this task fails, probably the files/ansible_authorized_keys pubkey isn't what it should be.
  gather_facts: yes

  tasks:
    - group_by: 'key={{ ansible_distribution_release }}'

- hosts: 'reimage_nfs'
  gather_facts: no

  tasks:
    - name: Configure minimal sources.list file
      lineinfile:
        dest: /etc/apt/sources.list
        line: 'deb {{ target_mirror }} {{ target_release }} {{ target_components }}'
        regexp: '^deb '
    - command: apt-get update
    - name: install boot packages
      apt: "pkg=grub-pc,kbd,console-setup,{{ pkg_linux_image }}{{ extra_packages }}"

# second play
#   we can connect as our service user, now set it up so that ansible can run
- hosts: 'reimage_nfs'
  gather_facts: no

  tasks:
    # needed for variable discovery
    - name: install lsb-release
      apt: name="lsb-release" state=present
      register: result
      ignore_errors: True

    - name: install python-apt (for lsb-release)
      command: aptitude install --assume-yes python-apt
      when: result|failed

    - name: install lsb-release (try again)
      apt: name="lsb-release" state=present
      when: result|failed

    - name: Create SSH directory
      file: path=/home/{{ ansible_role_account }}/.ssh state=directory owner={{ ansible_role_account }} mode=700

    - name: Copy authorized_keys for ansible remote user
      copy:
        src: files/ansible_authorized_keys
        dest: '/home/{{ ansible_role_account }}/.ssh/authorized_keys'
        owner: '{{ ansible_role_account }}'
        group: '{{ ansible_role_account }}'
        mode: 0400

# third play
#   setup system so that it's rebootable
- hosts: 'reimage_nfs'

  tasks:
    - lineinfile:
        dest: /etc/fstab
        line: '{{ dev_root }}  /  ext4  errors=remount-ro,user_xattr  0  1'
    - lineinfile:
        dest: /etc/fstab
        line: 'LABEL=boot /boot ext3 defaults 0 2'
    - when: USE_encryption|default(false)|bool
      block:
        - name: lookup dev_crypt's uuid
          command: 'blkid -s UUID -o value {{ dev_crypt }}'
          register: reg_dev_crypt_uuid
        - lineinfile:
            dest: /etc/crypttab
            line: 'crypt_root  UUID={{ reg_dev_crypt_uuid.stdout }}    none        luks'
          notify: update-initramfs
    - name: Create mtab symblink to give mount(1) the ability to know mounts
      file: path=/etc/mtab state=link src=/proc/mounts

    - lineinfile:
        dest: /etc/default/grub
        regexp: 'GRUB_CMDLINE_LINUX_DEFAULT='
        line: 'GRUB_CMDLINE_LINUX_DEFAULT="net.ifnames=0 biosdevname=0 ip={{ network.eth0.address }}::{{ network.eth0.gateway }}:{{ network.eth0.netmask }}:{{ inventory_hostname }}:eth0:none"'
      notify: update-grub
    - command: grub-install {{ item }}
      with_items: '{{ devices }}'

    - name: Configure /etc/network/interfaces
      template: src=templates/interfaces.j2 dest=/etc/network/interfaces

    - file: dest=/etc/initramfs-tools/root state=directory
    - file: dest=/etc/initramfs-tools/root/.ssh state=directory
    - name: Allow users to remotely authorize to dropbear while booting
      copy: src=files/cryptlock_authorized_keys dest=/etc/initramfs-tools/root/.ssh/authorized_keys
      notify: update-initramfs

#    - command: reboot
#      delegate_to: '{{ jumphost }}'

#    - name: waiting for server to come back
#      local_action: 'wait_for host={{ inventory_hostname }} port={{ ansible_ssh_port | default(22) }} state=started'
#      sudo: false

  handlers:
    - name: update-initramfs
      command: update-initramfs -k all -u
    - name: update-grub
      command: update-grub
